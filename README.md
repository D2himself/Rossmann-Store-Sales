# Rossmann Store Sales Prediction

## Project Objective

The primary objective of this project is to predict the daily sales of Rossmann drug stores across Europe up to six weeks in advance. Accurate sales predictions can help Rossmann store managers optimize their operations, inventory management, and staffing levels.


## Project Overview

This project leverages historical sales data from 1,115 Rossmann stores, along with information about store characteristics, promotions, and competition.  A Gradient Boosting Machine (GBM) model is trained to forecast future sales. The project involves data preprocessing, feature engineering, model training, hyperparameter tuning, and evaluation using the Root Mean Squared Error (RMSE) metric.

## Project Structure
- **`rossmann-store-sales/`**: This folder contains the raw data files provided for the Rossmann Store Sales competition.
    - `store.csv`: Information about each store, such as store type, assortment, and competition.
    - `train.csv`: Historical sales data for training the model.
    - `test.csv`: Data for which sales predictions need to be made.
    - `sample_submission.csv`: A sample submission file in the required format.
- **`submission.csv`**: This file contains the final sales predictions generated by the model, ready for submission to the competition.
- **`Rossmann_Store_Sales_Prediction.ipynb`**: This Jupyter Notebook contains the code for data preprocessing, feature engineering, model training, and prediction.



## Steps Followed

1. **Data Acquisition and Preprocessing**:
    - Download the Rossmann Store Sales dataset from Kaggle.
    - Merge the store and sales data.
    - Handle missing values.
    - Clean and preprocess the data for training.

2. **Feature Engineering**:
    - Extract relevant features from the existing data.
    - Create new features, such as competition duration and promotion duration.
    - Engineer features to improve model accuracy.

3. **Model Selection and Training**:
    - Choose the XGBoost library for GBM model implementation.
    - Train an XGBoost model on the training data.
    - Use K-Fold cross-validation to evaluate the model.
    - Tune the model's hyperparameters to optimize its performance.

4. **Prediction and Submission**:
    - Make predictions on the test dataset.
    - Prepare a submission file in the required format.
    - Submit the file for evaluation.

## Key Insights and Results
* **Feature Importance:** `Promo`, `CompetitionDistance`, `DayOfWeek` are among the most important features in predicting sales.
* **Model Performance:** The final model achieves a competitive RMSE score on the validation set and the test set.
* **K-Fold Cross Validation:**  Using K-Fold cross-validation improves the model's generalization performance.
* **Hyperparameter Tuning:** Tuning parameters such as `n_estimators`, `max_depth`, and `learning_rate` significantly affects the model's performance.


## Tools Used

- **Python**
- **Pandas**: For data manipulation and analysis.
- **Scikit-learn**: For data preprocessing and model evaluation.
- **XGBoost**: For building and training the Gradient Boosting Machine model.
- **LightGBM**: Alternative GBM model that was explored.
- **OpenDatasets**: For downloading Kaggle data.
